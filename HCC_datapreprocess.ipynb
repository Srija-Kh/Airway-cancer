{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e09141-4861-4f34-ba34-c43c305c68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from node2vec import Node2Vec\n",
    "import networkx as nx\n",
    "\n",
    "def Runnode2vec(filepath):\n",
    "    n2v = n2.SparseOTF(p=1, q=0.5, workers=4, verbose=True)\n",
    "    \n",
    "    # Edge list with weights\n",
    "    df = pd.read_csv(filepath, sep=\"\\t\")  \n",
    "    \n",
    "    # Normalize combined_score\n",
    "    df[\"combined_score\"] /= 1000  # Scale between 0 and 1\n",
    "    \n",
    "    df.to_csv(\"weighted_edges.txt\", sep=\" \", header=False, index=False)\n",
    "\n",
    "    # edge list with weights enabled\n",
    "    edge_list = n2v.read_edg(\"weighted_edges.txt\", weighted=True, directed=False)\n",
    "\n",
    "    # Generation of embeddings\n",
    "    emd = n2v.embed(dim=128, num_walks=15, walk_length=60, window_size=10, epochs=15)\n",
    "\n",
    "    # Debugging\n",
    "    print(\"Embedding generated. Type:\", type(emd))\n",
    "    print(\"Embedding content:\", emd)\n",
    "    print(\"SparseOTF attributes:\", dir(n2v))\n",
    "\n",
    "    # Handle node IDs\n",
    "    if hasattr(n2v, \"nodes\"):\n",
    "        n2v_emd = pd.DataFrame(emd, index=n2v.nodes)\n",
    "    else:\n",
    "        raise AttributeError(\"SparseOTF object does not have a method or attribute to access node IDs.\")\n",
    "    \n",
    "    # Rename columns\n",
    "    n2v_emd.columns = ['network_' + str(col) for col in n2v_emd.columns]\n",
    "\n",
    "    return n2v_emd.reset_index().rename(columns={\"index\": \"ensembl\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f408cac6-5209-4a75-ac44-57fa0f7943be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from node2vec import Node2Vec\n",
    "import networkx as nx\n",
    "\n",
    "def Runnode2vec(filepath):\n",
    "    # Edge list with weights\n",
    "    df = pd.read_csv(filepath, sep=\"\\t\", header=None, names=[\"source\", \"target\", \"weight\"])\n",
    "    \n",
    "    # Normalize combined_score\n",
    "    df[\"weight\"] /= 1000  # Scale between 0 and 1\n",
    "    \n",
    "    # Creation of a graph from the edge list\n",
    "    G = nx.from_pandas_edgelist(df, \"source\", \"target\", [\"weight\"], create_using=nx.Graph())\n",
    "    \n",
    "    # Initialize Node2Vec with optimized parameters\n",
    "    node2vec = Node2Vec(G, dimensions=128, walk_length=60, num_walks=15, workers=4, p=1, q=0.5)\n",
    "    \n",
    "    # Generate embeddings\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "    \n",
    "    # Extract embeddings\n",
    "    emd = pd.DataFrame([model.wv[str(node)] for node in G.nodes()], index=G.nodes())\n",
    "    emd.columns = [f'network_{i}' for i in range(emd.shape[1])]\n",
    "    \n",
    "    # Reset index\n",
    "    return emd.reset_index().rename(columns={\"index\": \"ensembl\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d57ac-380c-42bb-a7c9-1e6604df7cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def ImportDGN():\n",
    "    dgn = pd.read_csv(\"Liver_Summary_GDA_ALL.csv\")\n",
    "    dgn_dict = pd.read_csv(\"gda_dictionary.csv\", index_col=None)\n",
    "\n",
    "    score_threshold = 0.02\n",
    "    ei_threshold = 0.7\n",
    "\n",
    "    dgn = dgn[['gene', 'evidenceIndexGDA', 'scoreGDA']]\n",
    "    dgn = dgn.loc[dgn['scoreGDA'] >= score_threshold]\n",
    "    dgn = dgn.loc[dgn['evidenceIndexGDA'] > ei_threshold]\n",
    "    dgn.rename({'scoreGDA':'gda_score'}, axis=1, inplace=True)\n",
    "    dgn = dgn.merge(dgn_dict, on=\"gene\").drop(['gene'], axis=1)\n",
    "    dgn['gda_score'] = 1\n",
    "\n",
    "    return dgn[['ensembl', 'gda_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7218675-aa8b-4df2-a1d0-39eb6762e742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def parse_fraction(cell):\n",
    "    if pd.isna(cell):\n",
    "        return None\n",
    "    \n",
    "    nums = re.findall(r'\\d+(?:\\.\\d+)?', str(cell))\n",
    "    \n",
    "    if len(nums) < 2:\n",
    "        return None\n",
    "    \n",
    "    num = float(nums[0])\n",
    "    den = float(nums[1])\n",
    "    \n",
    "    return num / den if den != 0 else None\n",
    "\n",
    "\n",
    "def ImportGDC(file_path):\n",
    "    gdc = pd.read_csv(file_path)\n",
    "    fraction_cols = [\n",
    "        'SSM Affected Cases in Cohort',\n",
    "        'SSM Affected Cases Across the GDC',\n",
    "        'CNV_Gain',\n",
    "        'CNV_Loss'\n",
    "    ]\n",
    "\n",
    "    for col in fraction_cols:\n",
    "        gdc[col] = gdc[col].apply(parse_fraction)\n",
    "\n",
    "    gdc = gdc.rename(columns={\n",
    "        'SSM Affected Cases in Cohort': 'nih_ssm_in_cohort',\n",
    "        'SSM Affected Cases Across the GDC': 'nih_ssm_across_gdc',\n",
    "        'CNV_Gain': 'nih_cnv_gain',\n",
    "        'CNV_Loss': 'nih_cnv_loss',\n",
    "        'Gene_ID': 'ensembl',\n",
    "        'Mutations': '# Mutations'\n",
    "    })\n",
    "    drop_cols = ['Symbol', 'Name', 'Cytoband', 'Type', 'Annotations']\n",
    "    gdc = gdc.drop(columns=[c for c in drop_cols if c in gdc.columns])\n",
    "\n",
    "    return gdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f61ed3c-91a7-43a9-854a-ae3203d9fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def ImportHPA():\n",
    "    hpa = pd.read_csv(r\"hpa_gene_features.tsv\", sep='\\t').drop_duplicates(subset='Gene')\n",
    "\n",
    "    identifiers = [\n",
    "        \"Gene\",\n",
    "        \"Ensembl\"\n",
    "    ]\n",
    "    discrete_features = [\n",
    "        \"Protein class\",\n",
    "        \"Biological process\",\n",
    "        \"Molecular function\",\n",
    "        \"Disease involvement\",\n",
    "        \"Subcellular location\",\n",
    "    ]\n",
    "    continuous_features = [\n",
    "        \"Tissue RNA - liver [NX]\",\n",
    "        \"Single Cell Type RNA - Mucus-secreting cells [NX]\",\n",
    "        \"Single Cell Type RNA - Ito cells [NX]\",\n",
    "        \"Single Cell Type RNA - Kupffer cells [NX]\"\n",
    "    ]\n",
    "\n",
    "    hpa_features = hpa.loc[:, hpa.columns.isin(identifiers + discrete_features + continuous_features)]\n",
    "\n",
    "    # Normalization\n",
    "    for col in continuous_features:\n",
    "        hpa_features[col] = (hpa_features[col] - hpa_features[col].mean()) / hpa_features[col].std()\n",
    "\n",
    "    def explode(feature):\n",
    "        return feature.apply(lambda x: x.replace(' ', '').split(','))\n",
    "\n",
    "    hpa_clean = hpa.fillna('')\n",
    "    for ft in discrete_features:\n",
    "        hpa_clean[ft] = explode(hpa_clean[ft])\n",
    "\n",
    "    protein_class = hpa_clean[\"Protein class\"].explode().unique()\n",
    "    biological_process = hpa_clean[\"Biological process\"].explode().unique()\n",
    "    molecular_function = hpa_clean[\"Molecular function\"].explode().unique()\n",
    "    disease_involvement = hpa_clean[\"Disease involvement\"].explode().unique()\n",
    "    subcellular_location = hpa_clean[\"Subcellular location\"].explode().unique()\n",
    "    GO_features = np.concatenate([protein_class, biological_process, molecular_function, disease_involvement, subcellular_location])\n",
    "\n",
    "    RowFeatures = pd.DataFrame(data=0, index=hpa_clean['Ensembl'], columns=GO_features)\n",
    "    counter = 0\n",
    "\n",
    "    for index, row in RowFeatures.iterrows():\n",
    "        features = hpa_clean.iloc[counter][['Protein class', 'Biological process', 'Molecular function', 'Disease involvement', 'Subcellular location']].to_list()\n",
    "        flattened = [item for sublist in features for item in sublist if item]\n",
    "        for t in flattened:\n",
    "            row[t] = 1\n",
    "        counter += 1\n",
    "\n",
    "    # Truncated SVD\n",
    "    n_comp = 200\n",
    "    svd = TruncatedSVD(n_components=n_comp)\n",
    "    svdModel = svd.fit(RowFeatures)\n",
    "    visits_emb = svdModel.transform(RowFeatures)\n",
    "    hpa_reduced = pd.DataFrame(data=visits_emb, index=RowFeatures.index).reset_index(names=\"Ensembl\")\n",
    "\n",
    "    continuous_data = hpa_features[['Ensembl'] + continuous_features].drop_duplicates()\n",
    "    hpa_final = pd.merge(hpa_reduced, continuous_data, on='Ensembl', how='left')\n",
    "\n",
    "    #hpa_final = hpa_final.drop(columns=['Ensembl'])\n",
    "\n",
    "    hpa_final.columns = ['hpa_' + str(col) for col in hpa_final.columns]\n",
    "    hpa_final = hpa_final.rename({\n",
    "        'hpa_Ensembl': 'ensembl',\n",
    "        'hpa_Tissue RNA - liver [NX]': 'nx_tissue_rna_liver',\n",
    "        'hpa_Single Cell Type RNA - Mucus-secreting cells [NX]': 'nx_single_cell_type_mucus_secreting_cells',\n",
    "        'hpa_Single Cell Type RNA - Ito cells [NX]': 'nx_single_cell_type_ito_cells',\n",
    "        'hpa_Single Cell Type RNA - Kupffer cells [NX]': 'nx_single_cell_type_kupffer_cells'\n",
    "    }, axis=1)\n",
    "\n",
    "    return hpa_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ede7d1-397b-49ba-8af9-ee5481693848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def remove_redun(el, verbose=False):\n",
    "    if verbose:\n",
    "        print(\"Original Size: \", len(el))\n",
    "\n",
    "    el_new = el.iloc[:, 0:2].apply(sorted, axis=1)\n",
    "\n",
    "    el_new = pd.DataFrame.from_dict(dict(zip(el_new.index, el_new.values))).T \n",
    "\n",
    "    el_new = el_new.drop_duplicates()\n",
    "    if verbose:\n",
    "        postDrop = len(el_new)\n",
    "        print(\"After Dropping Duplicates: \", len(el_new), \"(-\", len(el)-postDrop, \")\")\n",
    "\n",
    "    el_new = el_new.merge(el, left_on=[el_new.columns[0],el_new.columns[1]],  right_on=[el.columns[0], el.columns[1]])\n",
    "    if verbose:\n",
    "        print(\"After Merging: \", len(el_new), \"(-\", postDrop-len(el_new), \")\")\n",
    "        print()\n",
    "\n",
    "    return el_new.iloc[:, 2:]\n",
    "\n",
    "def map_IDs(el, gmap, verbose = False, dropNaNvalues = True):\n",
    "    gp_map_f = gmap.set_index('#string_protein_id')['alias']\n",
    "\n",
    "    el_converted = el.reset_index(drop=True)\n",
    "\n",
    "    el_converted[el_converted.columns[0]] = el_converted[el_converted.columns[0]].map(gp_map_f)\n",
    "    el_converted[el_converted.columns[1]] = el_converted[el_converted.columns[1]].map(gp_map_f)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"NaN values per Column:\", el_converted[el_converted.columns[0]].isna().sum(), el_converted[el_converted.columns[1]].isna().sum())\n",
    "\n",
    "    if dropNaNvalues:\n",
    "        el_converted = el_converted.dropna()\n",
    "        if verbose:\n",
    "            print(\"New edge list size:\", len(el_converted), \"( -\", len(el)-len(el_converted), \")\")\n",
    "    \n",
    "    return el_converted\n",
    "\n",
    "def ImportSTRING():\n",
    "    el_map = pd.read_csv(r\"9606.protein.aliases.v12.0.txt\", sep=\"\\t\")\n",
    "    el = pd.read_csv(r\"9606.protein.links.v12.0_sc.txt\", sep=\" \")\n",
    "    el_map = el_map.loc[el_map.source == 'Ensembl_gene']\n",
    "\n",
    "    el = remove_redun(el, True)\n",
    "    el = map_IDs(el, el_map, verbose=True)\n",
    "\n",
    "    return el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7643cfa4-5c23-4de3-9a2d-6be9c6b1bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdc = ImportGDC(\"cnv_data.csv\")\n",
    "gdc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60ba47b-5f73-4ef9-b91d-5a6d4a800eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpa = ImportHPA()\n",
    "hpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8dc278-08bb-46ab-a2cf-9889f1543679",
   "metadata": {},
   "outputs": [],
   "source": [
    "el = ImportSTRING()\n",
    "el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576d2e92-2aed-4416-8f48-23e3fc2cd32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "master = hpa.merge(gdc, on=\"ensembl\")\n",
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2639dbb-1da4-4a3b-845e-61b3c5642286",
   "metadata": {},
   "outputs": [],
   "source": [
    "el_allgenes = pd.concat([el['protein1'], el['protein2']]).drop_duplicates()\n",
    "master = master.loc[master['ensembl'].isin(el_allgenes)]\n",
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1769d72-b80b-45f8-8c7a-742fdabbe4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "el_intersect = (\n",
    "    el.iloc[:, :3] \n",
    "    .merge(master[\"ensembl\"], right_on=\"ensembl\", left_on='protein1')\n",
    "    .drop(\"ensembl\", axis=1)\n",
    ")\n",
    "el_intersect = (\n",
    "    el_intersect\n",
    "    .merge(master[\"ensembl\"], right_on=\"ensembl\", left_on='protein2')\n",
    "    .drop(\"ensembl\", axis=1)\n",
    "    .rename(columns={'protein1': 'gene1', 'protein2': 'gene2'})\n",
    ")\n",
    "\n",
    "el = el_intersect.merge(el, right_on=['protein1', 'protein2'], left_on=['gene1', 'gene2']).drop(['protein1', 'protein2'], axis=1)\n",
    "el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1adbca-c44c-4ef8-89a9-e9b2a4664128",
   "metadata": {},
   "outputs": [],
   "source": [
    "el[['gene1', 'gene2']].to_csv('hcc_edge_list_latest.edg', index=False, header=False, sep='\\t') \n",
    "el.to_csv('hcc_edge_list_features_latest.edg', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826a4538-8a9a-44a5-82c7-f50bf1109a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "el['gene1'] = pd.to_numeric(el['gene1'], errors='coerce')\n",
    "el['gene2'] = pd.to_numeric(el['gene2'], errors='coerce')\n",
    "el['combined_score_x'] = pd.to_numeric(el['combined_score_x'], errors='coerce')\n",
    "\n",
    "el.dropna(inplace=True)\n",
    "\n",
    "genes_array = el[['gene1', 'gene2', 'combined_score_x']].to_numpy(dtype=np.int64)\n",
    "\n",
    "np.save('hcc_edge_list_latest.npy', genes_array)\n",
    "\n",
    "print(\"Numpy array saved with weights!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eedabb-6f4a-4fe4-b9db-fe4a9901b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgn = ImportDGN()\n",
    "dgn = dgn.loc[dgn['ensembl'].isin(master['ensembl'])]\n",
    "dgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab596e7-e096-4500-84dc-3dcca201a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Runnode2vec(\"hcc_edge_list_latest.edg\")\n",
    "master = master.merge(network, on='ensembl')\n",
    "master.to_csv(\"node_node2vec_data_latest.csv\", index=None)\n",
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410b4c2-51d5-484c-b294-ae54f662999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "master[\"gda_score\"] = np.nan  \n",
    "master.loc[master[\"ensembl\"].isin(dgn[\"ensembl\"]), \"gda_score\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56243d2-1c1d-4881-97a4-a83754a4ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ones = (master.iloc[:, -1] == 1).sum()\n",
    "print(\"Number of 1s in the last column:\", num_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0fd09f-5416-472f-a183-4322dc4cd509",
   "metadata": {},
   "outputs": [],
   "source": [
    "master.to_csv(\"200_HCC_node_network_embeddings_latest.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
