{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec7a46e-8376-4ef8-abbf-521f222985f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(314159)\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb32f606-ceba-4921-9bb3-44773ad9184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/user/lihc/prepro_20_01/')\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d86fd5-4073-4c38-8a51-ad3cc6bc7ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Loading\n",
    "edge_list = np.load(\"edge_list_latest1.npy\", allow_pickle=True)\n",
    "\n",
    "# Splitting\n",
    "edge_list = np.array([row[0].split(\",\") for row in edge_list[1:]])\n",
    "\n",
    "# Extracting the source nodes, target nodes, and combined scores\n",
    "protein1 = edge_list[:, 0]\n",
    "protein2 = edge_list[:, 1] \n",
    "combined_score = edge_list[:, 2].astype(np.float32)\n",
    "\n",
    "# Mapping\n",
    "protein_map = {protein: idx for idx, protein in enumerate(np.unique(np.concatenate((protein1, protein2))))}\n",
    "protein1 = np.vectorize(protein_map.get)(protein1)\n",
    "protein2 = np.vectorize(protein_map.get)(protein2)\n",
    "\n",
    "# Stacking  \n",
    "edges = np.stack([protein1, protein2], axis=0)\n",
    "edge_list = torch.tensor(edges, dtype=torch.long)\n",
    "edge_weight = torch.tensor(combined_score, dtype=torch.float32) \n",
    "\n",
    "print(\"Edge list shape:\", edge_list.shape)\n",
    "print(\"Edge weights shape:\", edge_weight.shape)\n",
    "print(\"Protein map:\", protein_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43189e89-569c-497b-b775-08fa9448186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '200_node_network_embeddings_latest.csv' \n",
    "node_dataset = pd.read_csv(data_path, index_col=0)\n",
    "node_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4749bae-07ea-4ced-a9bf-75bc45a245d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "xcell_path = \"gene_xcell_spearman_rho_ENSG.csv\"\n",
    "print(\"Loading xCell features from:\", xcell_path)\n",
    "\n",
    "xcell = pd.read_csv(xcell_path)\n",
    "\n",
    "if 'gene_name' in xcell.columns:\n",
    "    gene_col = 'gene_name'\n",
    "else:\n",
    "    gene_col = xcell.columns[0]\n",
    "\n",
    "xcell['ensembl'] = xcell[gene_col].astype(str).str.split('.').str[0]\n",
    "\n",
    "immune_cols = [c for c in xcell.columns if c not in [gene_col, 'ensembl']]\n",
    "\n",
    "print(f\"Detected immune features (total={len(immune_cols)}):\")\n",
    "print(immune_cols[:20])\n",
    "\n",
    "xcell_collapsed = (\n",
    "    xcell\n",
    "    .groupby('ensembl', as_index=True)[immune_cols]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "print(\"xCell table after collapsing duplicates:\", xcell_collapsed.shape)\n",
    "\n",
    "if 'Smooth muscle' in xcell_collapsed.columns:\n",
    "    xcell_collapsed = xcell_collapsed.drop(columns=['Smooth muscle'])\n",
    "    print(\"Dropped Smooth muscle column\")\n",
    "\n",
    "N_XCELL = 20   \n",
    "selected_cols = xcell_collapsed.columns[:N_XCELL]\n",
    "\n",
    "print(f\"Using top {N_XCELL} xCell immune features:\")\n",
    "print(selected_cols.tolist())\n",
    "\n",
    "xcell_reduced = xcell_collapsed[selected_cols]\n",
    "\n",
    "xcell_aligned = xcell_reduced.reindex(node_dataset.index)\n",
    "\n",
    "missing_pct = (xcell_aligned.isna().mean() * 100).round(2)\n",
    "print(\"Missing % per selected xCell feature:\\n\", missing_pct)\n",
    "\n",
    "xcell_filled = xcell_aligned.fillna(xcell_aligned.mean())\n",
    "\n",
    "xcell_filled.columns = [f\"xcell_{c}\" for c in xcell_filled.columns]\n",
    "\n",
    "node_dataset = pd.concat([node_dataset, xcell_filled], axis=1)\n",
    "\n",
    "node_dataset.to_csv(\"node_dataset_with_xcell_rho.csv\")\n",
    "print(\"Saved merged node_dataset_with_xcell_rho.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023c0252-4201-493a-a53d-8099533a5a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dataset.sort_index(inplace=True)\n",
    "node_dataset.reset_index(drop=False, inplace=True)\n",
    "assert((node_dataset.index.to_numpy()==np.arange(len(node_dataset))).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ecf59f-9322-4160-8dfd-db459b5ae1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = 'my_label'\n",
    "\n",
    "pos_label_col = 'gda_score'\n",
    "node_dataset[pos_label_col].fillna(0, inplace=True) \n",
    "pos_labels = pd.array([1 if row[pos_label_col] else None for id_, row in node_dataset.iterrows()], dtype='Int32')\n",
    "node_dataset[label_name] = pos_labels\n",
    "\n",
    "def sample_negatives(PU_labels):\n",
    "    '''randomly samples from the unlabeled samples'''\n",
    "\n",
    "    # sample same # as positives\n",
    "    num_pos = (PU_labels==1).sum()\n",
    "    neg_inds = PU_labels[PU_labels.isna()].sample(num_pos).index\n",
    "\n",
    "    return neg_inds\n",
    "\n",
    "neg_label_inds = sample_negatives(node_dataset[label_name])\n",
    "node_dataset.loc[neg_label_inds, label_name] = 0\n",
    "\n",
    "node_dataset[label_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de86a603-e8e2-4651-8eb4-8b83863e52cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dataset.set_index(node_dataset.columns[0], inplace=True)\n",
    "node_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc9ec3-889b-48c6-b436-4640f5aaa1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = node_dataset.columns[-1]\n",
    "node_dataset[label_col] = node_dataset[label_col].astype('Int32')\n",
    "\n",
    "if 'gda_score' in node_dataset.columns:\n",
    "    node_dataset = node_dataset.drop(columns=['gda_score'])\n",
    "\n",
    "# HPA + Network + Other features\n",
    "node_feat_cols = node_dataset.columns[:-1].tolist()  # All columns except the label\n",
    "\n",
    "# Subset of node features + labels\n",
    "node_data = node_dataset[node_feat_cols + [label_col]]\n",
    "\n",
    "# Convertion\n",
    "X = torch.Tensor(node_data[node_feat_cols].select_dtypes(include=[np.number]).to_numpy(dtype=np.float32))\n",
    "\n",
    "\n",
    "# Filling NaN with -1\n",
    "y = node_data[label_col].fillna(-1).astype('int')\n",
    "y = torch.Tensor(y).type(torch.int64)\n",
    "\n",
    "# Restriction\n",
    "node_data_labeled = node_data[node_data[label_col].notna()]\n",
    "node_data_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ea275-c6e1-47d9-8b44-077bf7581bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Extraction\n",
    "X_myIDs = node_data_labeled.index.to_numpy() \n",
    "labels = node_data_labeled[label_col].to_numpy() \n",
    "\n",
    "test_size = 0.2\n",
    "val_size = 0.1 * (1 / (1 - test_size))\n",
    "\n",
    "# Stratified train-test split\n",
    "myIDs_train_val, myIDs_test = train_test_split(X_myIDs, test_size=test_size, shuffle=True, stratify=labels)\n",
    "labels_train_val = node_data_labeled.loc[myIDs_train_val, label_col].to_numpy()\n",
    "myIDs_train, myIDs_val = train_test_split(myIDs_train_val, test_size=val_size, shuffle=True, stratify=labels_train_val)\n",
    "\n",
    "id_to_idx = {id_: idx for idx, id_ in enumerate(node_data.index)}\n",
    "\n",
    "train_idx = np.array([id_to_idx[i] for i in myIDs_train])\n",
    "val_idx = np.array([id_to_idx[i] for i in myIDs_val])\n",
    "test_idx = np.array([id_to_idx[i] for i in myIDs_test])\n",
    "\n",
    "# Boolean masks\n",
    "n_nodes = len(node_data)\n",
    "\n",
    "train_mask = np.zeros(n_nodes, dtype=bool)\n",
    "train_mask[train_idx] = True\n",
    "train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
    "\n",
    "val_mask = np.zeros(n_nodes, dtype=bool)\n",
    "val_mask[val_idx] = True\n",
    "val_mask = torch.tensor(val_mask, dtype=torch.bool)\n",
    "\n",
    "test_mask = np.zeros(n_nodes, dtype=bool)\n",
    "test_mask[test_idx] = True\n",
    "test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
    "\n",
    "print(f\"Number of training nodes: {train_mask.sum().item()}\")\n",
    "print(f\"Number of validation nodes: {val_mask.sum().item()}\")\n",
    "print(f\"Number of test nodes: {test_mask.sum().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fe77dc-0804-492c-94b1-f71a26c801e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=X, y=y, edge_index=edge_list, edge_attr=edge_weight)  # Add edge weights\n",
    "\n",
    "num_classes = 2\n",
    "num_features = X.shape[1]\n",
    "\n",
    "data.train_mask = train_mask\n",
    "data.val_mask = val_mask\n",
    "data.test_mask = test_mask\n",
    "assert y.shape[0] == X.shape[0]\n",
    "\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe81eee-23a2-4a21-b4eb-d9dea514f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = \"\" #API Key\n",
    "os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "\n",
    "config = {\n",
    "    \"dataset\": \"\",\n",
    "    \"machine\": \"online cluster\",\n",
    "    \"model\": \"CNN\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "\n",
    "wandb.init(project=\"offline-demo\")\n",
    "\n",
    "for i in range(100):\n",
    "    wandb.log({\"accuracy\": i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a110afdc-bbcc-4e74-b3df-0b83f846b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class GNNModel(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes, hidden_dense, GNN_conv_layer=GCNConv, dropout_rate=0.4, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialization\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GNN_conv_layer(in_channels=num_features, out_channels=hidden_channels[0], **kwargs))\n",
    "\n",
    "        for c1, c2 in zip(hidden_channels[:-1], hidden_channels[1:]):\n",
    "            self.convs.append(GNN_conv_layer(in_channels=c1, out_channels=c2, **kwargs))\n",
    "\n",
    "        self.dense1 = torch.nn.Linear(hidden_channels[-1], hidden_dense)\n",
    "        self.dense_out = torch.nn.Linear(hidden_dense, num_classes)\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index, edge_weight=edge_weight)\n",
    "            x = x.relu()\n",
    "            x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "        x = self.dense1(x)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "        x = self.dense_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class WeightedSAGEConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='mean')\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "        self.lin_update = torch.nn.Linear(in_channels + out_channels, out_channels)\n",
    "        self.last_messages = None \n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x_transformed = self.lin(x)\n",
    "        self.last_messages = None\n",
    "        out = self.propagate(edge_index=edge_index, x=x_transformed, edge_weight=edge_weight)\n",
    "        out = self.lin_update(torch.cat([out, x], dim=1))\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, edge_weight):\n",
    "        messages = edge_weight.view(-1, 1) * x_j\n",
    "        self.last_messages = messages.detach().cpu()\n",
    "        return messages\n",
    "\n",
    "\n",
    "class LitGNN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model_name, num_features, hidden_channels, num_classes, hidden_dense, GNN_conv_layer, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters() \n",
    "        self.model_name = model_name\n",
    "        self.model = GNNModel(num_features, hidden_channels, num_classes, hidden_dense, GNN_conv_layer, dropout_rate)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.validation_step_outputs = []  \n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        return self.model(x, edge_index, edge_weight)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        out = self(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        valid_indices = batch.y >= 0\n",
    "\n",
    "        if valid_indices.any():\n",
    "            loss = self.criterion(out[valid_indices], batch.y[valid_indices])\n",
    "        else:\n",
    "            loss = torch.tensor(0.0, requires_grad=True, device=self.device)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        out = self(batch.x, batch.edge_index, edge_weight=batch.edge_attr)\n",
    "\n",
    "        valid_indices = batch.y >= 0\n",
    "\n",
    "        if valid_indices.any():\n",
    "            loss = self.criterion(out[valid_indices], batch.y[valid_indices])\n",
    "            acc = (out[valid_indices].argmax(dim=1) == batch.y[valid_indices]).float().mean()\n",
    "        else:\n",
    "            loss = torch.tensor(0.0, device=self.device)\n",
    "            acc = torch.tensor(0.0, device=self.device)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        # Store outputs for later use\n",
    "        self.validation_step_outputs.append({\"val_loss\": loss, \"val_acc\": acc})\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_acc_mean = torch.stack([x[\"val_acc\"] for x in self.validation_step_outputs]).mean()\n",
    "        self.log(\"val_acc_epoch\", val_acc_mean, prog_bar=True)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        out = self(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        valid_indices = batch.y >= 0\n",
    "\n",
    "        if valid_indices.any():\n",
    "            loss = self.criterion(out[valid_indices], batch.y[valid_indices])\n",
    "            acc = (out[valid_indices].argmax(dim=1) == batch.y[valid_indices]).float().mean()\n",
    "        else:\n",
    "            loss = torch.tensor(0.0, device=self.device)\n",
    "            acc = torch.tensor(0.0, device=self.device)\n",
    "\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "        return {\"test_loss\": loss, \"test_acc\": acc}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        test_acc_mean = torch.stack([x[\"test_acc\"] for x in outputs]).mean()\n",
    "        self.log(\"test_acc_epoch\", test_acc_mean, prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d519e4be-b430-4105-9766-63ee531ef41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aca894-5278-4fc2-9dd0-c76f6b6994ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, ModelSummary, EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "import datetime\n",
    "\n",
    "AVAIL_GPUS = 0 \n",
    "MAX_EPOCHS = 200 \n",
    "NUM_TRIALS = 25  \n",
    "GNN_conv_layer=WeightedSAGEConv \n",
    "\n",
    "# Loop through trials\n",
    "for trial in range(1, NUM_TRIALS + 1):\n",
    "    model_name = f'gat_{datetime.datetime.today().strftime(\"%Y-%m-%d\")}_trial_{trial}'\n",
    "    logger = WandbLogger(name=model_name, project=\"Project X\", log_model=\"all\")\n",
    "\n",
    "    # Initialization\n",
    "    model = LitGNN(\n",
    "        model_name=\"GraphSAGE\", \n",
    "        num_features=num_features, \n",
    "        hidden_channels=[128], \n",
    "        num_classes=num_classes, \n",
    "        hidden_dense=64, \n",
    "        GNN_conv_layer=GNN_conv_layer, \n",
    "        dropout_rate=0.3\n",
    "    )\n",
    "\n",
    "    train_data_loader = DataLoader([data], batch_size=1, num_workers=3) \n",
    "    val_data_loader = DataLoader([data], batch_size=1, num_workers=3)   \n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        save_weights_only=True, \n",
    "        mode=\"max\", \n",
    "        monitor=\"val_acc\", \n",
    "        dirpath=f\"checkpoints/trial_{trial}\", \n",
    "        filename=\"{epoch:02d}-{val_acc:.2f}\" \n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        callbacks=[\n",
    "            checkpoint_callback, \n",
    "            EarlyStopping(monitor=\"val_acc\", patience=20, verbose=True, mode=\"max\"), \n",
    "            ModelSummary(max_depth=3)  \n",
    "        ],\n",
    "        devices=1, \n",
    "        accelerator=\"cpu\", \n",
    "        max_epochs=MAX_EPOCHS,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    # Training\n",
    "    trainer.fit(model, train_dataloaders=train_data_loader, val_dataloaders=val_data_loader)\n",
    "\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "    if best_model_path:\n",
    "        model = LitGNN.load_from_checkpoint(\n",
    "            best_model_path,\n",
    "            model_name=\"GraphSAGE\",\n",
    "            num_features=num_features,\n",
    "            hidden_channels=[128],\n",
    "            num_classes=num_classes,\n",
    "            hidden_dense=64,\n",
    "            GNN_conv_layer=GNN_conv_layer,\n",
    "            dropout_rate=0.3\n",
    "        )\n",
    "        print(f\"Trial {trial}: Loaded model from checkpoint: {best_model_path}\")\n",
    "    else:\n",
    "        print(f\"Trial {trial}: No checkpoint found. Training from scratch.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7f622-990e-4f20-b835-27cc8ad3fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "def to_numpy(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x\n",
    "    return x.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "train_accuracies, train_precisions, train_recalls, train_f1s = [], [], [], []\n",
    "test_accuracies, test_precisions, test_recalls, test_f1s = [], [], [], []\n",
    "\n",
    "train_aucs, test_aucs = [], []\n",
    "train_auprs, test_auprs = [], []\n",
    "\n",
    "\n",
    "\n",
    "for trial in range(1, NUM_TRIALS + 1):\n",
    "    print(f\"\\nEvaluating Trial {trial}\")\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    data = data.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(\n",
    "            data.x,\n",
    "            data.edge_index,\n",
    "            data.edge_attr\n",
    "        )\n",
    "\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "\n",
    "    train_mask = data.train_mask\n",
    "    y_train = data.y[train_mask]\n",
    "    preds_train = logits[train_mask].argmax(dim=1)\n",
    "    probs_train = probs[train_mask][:, 1]\n",
    "\n",
    "    train_report = classification_report(\n",
    "        to_numpy(y_train),\n",
    "        to_numpy(preds_train),\n",
    "        labels=[0, 1],\n",
    "        target_names=[\"negative\", \"positive\"],\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    train_accuracies.append(train_report[\"accuracy\"])\n",
    "    train_precisions.append(train_report[\"positive\"][\"precision\"])\n",
    "    train_recalls.append(train_report[\"positive\"][\"recall\"])\n",
    "    train_f1s.append(train_report[\"positive\"][\"f1-score\"])\n",
    "\n",
    "    if len(torch.unique(y_train)) > 1:\n",
    "        train_aucs.append(\n",
    "            roc_auc_score(to_numpy(y_train), to_numpy(probs_train))\n",
    "        )\n",
    "        train_auprs.append(\n",
    "            average_precision_score(to_numpy(y_train), to_numpy(probs_train))\n",
    "        )\n",
    "    else:\n",
    "        train_aucs.append(np.nan)\n",
    "        train_auprs.append(np.nan)\n",
    "\n",
    "\n",
    "    test_mask = data.test_mask\n",
    "    y_test = data.y[test_mask]\n",
    "    preds_test = logits[test_mask].argmax(dim=1)\n",
    "    probs_test = probs[test_mask][:, 1]\n",
    "\n",
    "    test_report = classification_report(\n",
    "        to_numpy(y_test),\n",
    "        to_numpy(preds_test),\n",
    "        labels=[0, 1],\n",
    "        target_names=[\"negative\", \"positive\"],\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    test_accuracies.append(test_report[\"accuracy\"])\n",
    "    test_precisions.append(test_report[\"positive\"][\"precision\"])\n",
    "    test_recalls.append(test_report[\"positive\"][\"recall\"])\n",
    "    test_f1s.append(test_report[\"positive\"][\"f1-score\"])\n",
    "\n",
    "    if len(torch.unique(y_test)) > 1:\n",
    "        test_aucs.append(\n",
    "            roc_auc_score(to_numpy(y_test), to_numpy(probs_test))\n",
    "        )\n",
    "        test_auprs.append(\n",
    "            average_precision_score(to_numpy(y_test), to_numpy(probs_test))\n",
    "        )\n",
    "    else:\n",
    "        test_aucs.append(np.nan)\n",
    "        test_auprs.append(np.nan)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nAggregated Metrics (Mean ± Std)\")\n",
    "\n",
    "print(f\"Train Accuracy : {np.mean(train_accuracies):.4f} ± {np.std(train_accuracies):.4f}\")\n",
    "print(f\"Train Precision: {np.mean(train_precisions):.4f} ± {np.std(train_precisions):.4f}\")\n",
    "print(f\"Train Recall   : {np.mean(train_recalls):.4f} ± {np.std(train_recalls):.4f}\")\n",
    "print(f\"Train F1       : {np.mean(train_f1s):.4f} ± {np.std(train_f1s):.4f}\")\n",
    "print(f\"Train AUROC    : {np.nanmean(train_aucs):.4f} ± {np.nanstd(train_aucs):.4f}\")\n",
    "print(f\"Train AUPRC    : {np.nanmean(train_auprs):.4f} ± {np.nanstd(train_auprs):.4f}\")\n",
    "\n",
    "print(f\"Test Accuracy  : {np.mean(test_accuracies):.4f} ± {np.std(test_accuracies):.4f}\")\n",
    "print(f\"Test Precision : {np.mean(test_precisions):.4f} ± {np.std(test_precisions):.4f}\")\n",
    "print(f\"Test Recall    : {np.mean(test_recalls):.4f} ± {np.std(test_recalls):.4f}\")\n",
    "print(f\"Test F1        : {np.mean(test_f1s):.4f} ± {np.std(test_f1s):.4f}\")\n",
    "print(f\"Test AUROC     : {np.nanmean(test_aucs):.4f} ± {np.nanstd(test_aucs):.4f}\")\n",
    "print(f\"Test AUPRC     : {np.nanmean(test_auprs):.4f} ± {np.nanstd(test_auprs):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
